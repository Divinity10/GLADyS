# PoC Validation Roadmap

**Last Updated**: 2026-01-24

## Purpose

This document defines what the Proof of Concept must validate to confirm GLADyS is feasible. Rather than proving abstract mechanisms work, we prove the system can handle real-world tasks that humans find trivial.

The PoC is successful when we can demonstrate (with mocked sensors/actuators) that the architecture supports basic assistant functionality.

---

## North Star Scenarios

These scenarios guide what we build. Each exposes layers that must work.

### Scenario 1: "Is Steve online?"

**User asks**: "Is Steve online?"

**Expected flow**:
1. Parse query â†’ identify intent (check person's online status)
2. Entity lookup â†’ Steve is a friend
3. Relationship lookup â†’ Steve has character "Buggy" in Minecraft
4. Context check â†’ Minecraft is currently running
5. Skill routing â†’ Minecraft skill can check player status
6. Execution â†’ Query Minecraft for Buggy's status
7. Response â†’ "Yes, Steve (Buggy) is online in Minecraft"

**Why this scenario matters**:
- Requires semantic memory (who is Steve? what characters?)
- Requires skill discovery (what can check online status?)
- Requires multi-step reasoning (Steve â†’ character â†’ game â†’ check)
- Trivial for humans, exposes real complexity for the system

**Layer Requirements**:

| Layer | Component | What It Does | Status |
|-------|-----------|--------------|--------|
| 0 | Storage | PostgreSQL stores all data | âœ… Proven |
| 1a | Episodic Memory | Store/retrieve events | âœ… Proven |
| 1b | Semantic Memory | Store/retrieve entities & relationships | ğŸ”´ Not built |
| 2 | Retrieval | Query relevant entities, traverse relationships | ğŸ”´ Not proven |
| 3 | Skill Registry | Know what skills exist and their capabilities | ğŸ”´ Not built |
| 4 | Routing/Planning | Connect query to correct skill | ğŸ”´ Not built |
| 5 | Execution | Call skill, return result | ğŸ”´ Not built |

---

### Scenario 2: "Send an email to Mike"

**User asks**: "Send an email to Mike saying I'll be late"

**Expected flow**:
1. Parse query â†’ identify intent (send email)
2. Entity lookup â†’ Mike is [specific person with email]
3. Skill routing â†’ Email skill can send messages
4. Execution â†’ Compose and send email
5. Confirmation â†’ "Email sent to Mike"

**Why this scenario matters**:
- Requires entity resolution (which Mike?)
- Requires skill with side effects (actually sends something)
- Common assistant task

**Layer Requirements**:

| Layer | Component | What It Does | Status |
|-------|-----------|--------------|--------|
| 1b | Semantic Memory | Know Mike's email address | ğŸ”´ Not built |
| 3 | Skill Registry | Email skill registered | ğŸ”´ Not built |
| 5 | Execution | Call email actuator | ğŸ”´ Not built |

---

### Scenario 3: "What's on my calendar tomorrow?"

**User asks**: "What's on my calendar tomorrow?"

**Expected flow**:
1. Parse query â†’ identify intent (calendar query)
2. Skill routing â†’ Calendar skill can query events
3. Execution â†’ Query calendar for tomorrow's events
4. Response â†’ List of events

**Why this scenario matters**:
- Read-only query (simpler than email)
- Time-based reasoning ("tomorrow")
- Common assistant task

**Layer Requirements**:

| Layer | Component | What It Does | Status |
|-------|-----------|--------------|--------|
| 3 | Skill Registry | Calendar skill registered | ğŸ”´ Not built |
| 5 | Execution | Call calendar sensor | ğŸ”´ Not built |

---

### Scenario 4: Learning Loop (Original PoC Focus)

**Flow**: Event â†’ LLM Reasoning â†’ Feedback â†’ Heuristic â†’ Skip LLM next time

**Why this scenario matters**:
- The differentiator: system learns from experience
- Converts slow reasoning to fast heuristics
- Proves adaptive behavior works

**Layer Requirements**:

| Layer | Component | What It Does | Status |
|-------|-----------|--------------|--------|
| 1a | Episodic Memory | Store events | âœ… Proven |
| 1c | Procedural Memory | Store heuristics | âœ… Proven |
| 2 | Heuristic Matching | Find matching heuristics | âœ… Proven (word overlap) |
| 4 | LLM Integration | Reason about events | âœ… Proven (Ollama) |
| 4 | Pattern Extraction | Extract heuristic from feedback | âš ï¸ Partially proven |

---

### Scenario 5: "The Second Time is Faster" (Learning Experience)

**User experience**:

```
First time:
  User: "Is Steve online?"
  System: [LLM reasons: Steve â†’ Buggy â†’ Minecraft â†’ check] (2-3 seconds)
  Response: "Steve (Buggy) is online in Minecraft"
  User: "Thanks!" (positive feedback)
  System: [Extracts pattern, stores heuristic]

Second time (next day):
  User: "Is Steve online?"
  System: [Heuristic fires, skips LLM] (<100ms)
  Response: "Steve (Buggy) is online in Minecraft"
```

**Why this scenario matters**:
- Shows learning from user perspective (not just mechanism)
- Proves patterns generalize (works again later)
- Performance improvement is visible (2s â†’ 100ms)
- The differentiator in action

**Layer Requirements**:

| Layer | Component | What It Does | Status |
|-------|-----------|--------------|--------|
| All from Scenario 1 | â€” | Full query flow | ğŸ”´ Not built |
| 4b | Pattern Extraction | LLM generates useful heuristic | âš ï¸ Quality untested |
| 1c | Heuristic Persistence | Survives restart | âœ… Proven (PostgreSQL) |
| 2c | Natural Language Matching | Handles query variations | âš ï¸ Word overlap only |

---

### Scenario 6: Proactive Sensor Response

**Sensor event**: Temperature sensor reports 60Â°F (dropped from 72Â°F)

**Expected flow**:
1. Sensor sends event â†’ Orchestrator receives
2. Salience evaluation â†’ High (temperature drop is significant)
3. Heuristic check â†’ "When temp drops below 65Â°F, adjust thermostat"
4. Action â†’ Call thermostat actuator to increase heat
5. Notification â†’ "Temperature dropped to 60Â°F. Adjusting thermostat."

**Why this scenario matters**:
- System-initiated, not user-initiated (proactive)
- Proves the "always observing brain" architecture
- IoT/smart home is a primary use case
- Event-driven, not query-driven

**Layer Requirements**:

| Layer | Component | What It Does | Status |
|-------|-----------|--------------|--------|
| 0 | Sensor Integration | Receive sensor events | ğŸ”´ Not built |
| 1a | Episodic Memory | Store temperature events | âœ… Proven |
| 2c | Heuristic Matching | Match condition to event | âœ… Proven |
| 5 | Actuator Execution | Call thermostat | ğŸ”´ Not built |
| â€” | Salience Thresholds | Determine significance | âš ï¸ Structure exists |

---

### Scenario 7: Pattern Detection / Habituation

**Observation**: User has manually turned on porch light at sunset 5 times this week

**Expected flow**:
1. System observes repeated pattern
2. Confidence builds over repetitions
3. System suggests: "I notice you turn on the porch light at sunset. Should I do this automatically?"
4. User confirms â†’ Creates automation heuristic
5. Next sunset â†’ System acts proactively

**Why this scenario matters**:
- System learns without explicit feedback
- Proves habituation/pattern detection works
- Proactive suggestion (not just reaction)
- User remains in control (confirms before automating)

**Layer Requirements**:

| Layer | Component | What It Does | Status |
|-------|-----------|--------------|--------|
| 1a | Episodic Memory | Track repeated events | âœ… Proven |
| 2a | Pattern Detection | Identify recurring patterns | ğŸ”´ Not built |
| â€” | Confidence Accumulation | Build confidence over time | ğŸ”´ Not built |
| 4 | Suggestion Generation | Propose automation | ğŸ”´ Not built |

---

### Scenario 8: Disambiguation

**User asks**: "Call Mike"

**Expected flow**:
1. Parse query â†’ intent is "call someone named Mike"
2. Entity lookup â†’ Multiple Mikes exist (Mike Mulcahy, Mike Smith)
3. System asks: "Which Mike? Mike Mulcahy or Mike Smith?"
4. User: "Mulcahy"
5. Execution â†’ Initiate call to Mike Mulcahy

**Why this scenario matters**:
- Handles ambiguous requests gracefully
- Proves system can ask clarifying questions
- Common real-world situation
- Tests entity resolution with multiple matches

**Layer Requirements**:

| Layer | Component | What It Does | Status |
|-------|-----------|--------------|--------|
| 1b | Semantic Memory | Store multiple entities with same name | ğŸ”´ Not built |
| 2b | Entity Resolution | Detect ambiguity | ğŸ”´ Not built |
| â€” | Clarification Flow | Ask user, process response | ğŸ”´ Not built |
| 4 | Context Tracking | Remember clarification in conversation | ğŸ”´ Not built |

---

### Scenario 9: Negative Feedback / Unlearning

**User experience**:

```
Event: Temperature drops to 68Â°F
System: [Heuristic fires] "Adjusting thermostat to 72Â°F"
User: "No, don't do that. I like it cool."
System: [Decreases heuristic confidence]
         "Got it. I won't adjust the thermostat when it's 68Â°F."

Next time: Temperature drops to 68Â°F
System: [Heuristic confidence too low, doesn't fire]
        [May ask: "Temperature is 68Â°F. Want me to adjust the thermostat?"]
```

**Why this scenario matters**:
- Completes the learning loop (positive AND negative feedback)
- System can unlearn bad heuristics
- User corrections improve the system
- Proves TD learning / confidence adjustment works

**Layer Requirements**:

| Layer | Component | What It Does | Status |
|-------|-----------|--------------|--------|
| 1c | Procedural Memory | Update heuristic confidence | ğŸ”´ TD learning not built |
| â€” | Credit Assignment | Know which heuristic caused action | ğŸ”´ Not built |
| â€” | Confidence Threshold | Don't fire low-confidence heuristics | âš ï¸ Threshold exists (0.5) |
| 4 | Feedback Processing | Handle negative feedback | âš ï¸ RPC exists, no confidence update |

---

## Layer Status Summary

| Layer | Component | Description | Status | Proven By |
|-------|-----------|-------------|--------|-----------|
| 0 | Storage | PostgreSQL + pgvector | âœ… Done | Local DB working |
| 1a | Episodic Memory | Event storage/retrieval | âœ… Done | Events store, query works |
| 1b | Semantic Memory | Entity + relationship storage | ğŸ”´ Not built | â€” |
| 1c | Procedural Memory | Heuristic storage | âœ… Done | Heuristics store to DB |
| 2a | Event Retrieval | Query events by time/similarity | âš ï¸ Partial | Time works, similarity untested |
| 2b | Entity Retrieval | Query entities, traverse relationships | ğŸ”´ Not built | â€” |
| 2c | Heuristic Matching | Match events to heuristics | âœ… Done | test_killer_feature.py |
| 3 | Skill Registry | Capability discovery | ğŸ”´ Not built | â€” |
| 4a | LLM Reasoning | Process events with LLM | âœ… Done | Executive stub + Ollama |
| 4b | Pattern Extraction | Extract heuristic from feedback | âš ï¸ Partial | Works, quality untested |
| 4c | Query Routing | Route queries to skills | ğŸ”´ Not built | â€” |
| 5 | Skill Execution | Call sensors/actuators | ğŸ”´ Not built | â€” |

---

## Next Steps (Ordered)

### Phase 1: Semantic Memory Foundation
**Goal**: Prove we can store and retrieve entities with relationships

1. Design entity schema (entities table, relationships table)
2. Add entity proto messages
3. Implement store/retrieve RPCs
4. Test: Store Steve â†’ Buggy â†’ Minecraft, query it back

**Success Criteria**:
- Can store entity with type and attributes
- Can store relationship between entities
- Can query entity by name and get related entities
- Can traverse relationships (Steve â†’ characters â†’ games)

### Phase 2: Episodic Retrieval Quality
**Goal**: Prove similarity-based retrieval works

1. Store 10-15 varied events
2. Query by similarity
3. Verify related events return, unrelated don't

**Success Criteria**:
- Semantic similarity captures meaning (not just keywords)
- Threshold tuning gives reasonable precision/recall

### Phase 3: Skill Registry (Mock)
**Goal**: Prove skills can advertise capabilities

1. Define skill manifest format (YAML)
2. Create mock Minecraft skill manifest
3. Load manifests, query capabilities

**Success Criteria**:
- Can query "what skill checks player online status?"
- Returns correct skill with correct method

### Phase 4: End-to-End Query Flow
**Goal**: Prove "Is Steve online?" works with mocks

1. Wire together: query â†’ entity lookup â†’ skill routing â†’ mock response
2. Test full flow

**Success Criteria**:
- Query returns correct answer
- All layers participate correctly

---

## Test Inventory

| Test | File | What It Proves |
|------|------|----------------|
| Heuristic storage | test_heuristic_flow.py | LLM extracts pattern, stores to DB |
| Heuristic matching | test_killer_feature.py | Matching skips LLM, 42x speedup |
| Entity storage | (not built) | Semantic memory works |
| Similarity retrieval | (not built) | Embeddings capture meaning |
| Skill discovery | (not built) | Capability registry works |
| E2E query | (not built) | Full "Is Steve online?" flow |

---

## Open Questions

1. **Entity schema**: Graph DB style (nodes + edges) or relational with foreign keys?
2. **Skill manifest format**: YAML? JSON? Proto?
3. **Query routing**: Rules-based or LLM-based?
4. **Ambiguity handling**: What if there are two Steves?

---

## Relationship to ADRs

This roadmap validates the architecture defined in the ADRs:

- **ADR-0001**: Brain-inspired architecture (sensor â†’ salience â†’ executive)
- **ADR-0004**: Memory hierarchy (episodic, semantic, procedural)
- **ADR-0010**: Learning pipeline (heuristic formation)
- **ADR-0003**: Plugin/skill packs (capability manifests)

The PoC proves these architectural decisions are implementable and effective.
