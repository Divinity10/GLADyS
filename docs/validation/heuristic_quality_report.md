# Validation Report: Heuristic Extraction Quality (Option B)

**Date**: 2026-01-24
**Evaluator**: Gemini CLI
**Subject**: Quality of heuristics generated by `PATTERN_EXTRACTION_PROMPT` in `src/services/executive/gladys_executive/server.py`.

## Overview

This report validates whether the LLM prompt used for "learning" produces usable, semantic heuristics. We simulated 8 diverse scenarios across Gaming, Smart Home, Productivity, and Development domains.

**Overall Assessment**: âœ… **PASS (High Quality)**
The current prompt structure produces remarkably stable, generalizable heuristics. The separation of `condition` (trigger) and `action` (response) is consistent. The LLM successfully generalizes specific details (e.g., "3 hearts") into semantic concepts ("critically low health").

## Scenario Results

| ID | Domain | Input Context | Extracted Condition (System 1 Trigger) | Quality | Notes |
|----|--------|---------------|----------------------------------------|---------|-------|
| MC-01 | Gaming | Player health dropped to 3 hearts after creeper explosion | `player health critically low after combat damage` | **Good** | Excellent generalization. Removes specific numbers ("3 hearts") which aids fuzzy matching. |
| HOME-01 | Home | Lights set to 100%, user manually set to 50% | `user manually dims lights immediately after automated high brightness` | **Marginal** | "Immediately" is a temporal constraint that vector search can't check easily. May require a specialized "Pattern Detector". |
| WORK-01 | Productivity | Meeting in 5m, user Idle | `meeting starting soon while user status is idle` | **Good** | Captures compound state well. |
| SOC-01 | Social | Friend online after 7 days | `friend comes online after long absence` | **Good** | "Long absence" is a perfect semantic match for the vector store. |
| SYS-01 | System | RAM usage 95% | `system RAM usage critically high` | **Good** | Robust. |
| GAME-02 | Gaming | New high score | `user achieves new high score` | **Marginal** | Too generic? Might fire for *any* game, leading to repetitive behavior. Needs domain scoping (e.g., "in arcade game"). |
| DEV-01 | Dev | Build failed: segfault | `build fails with segmentation fault error` | **Good** | Highly specific semantic concept, distinct from "syntax error". |
| HOME-02 | Home | Motion at 2AM (Silent) | `motion detected late at night` | **Good** | Action extracted was `"type": "suppress"`, correctly identifying the *negative* action. |

## Findings & Recommendations

### 1. Strengths
*   **Generalization**: The prompt instruction `(avoid specific names/numbers)` is working. The LLM consistently strips IDs and exact values.
*   **Semantic Density**: The conditions are "dense" with meaning ("critically low", "long absence"), which will work very well with the `all-MiniLM-L6-v2` embedding model.
*   **Action Types**: The LLM naturally categorizes actions (`alert`, `suggestion`, `suppress`), which maps cleanly to our response types.

### 2. Weaknesses / Risks
*   **Temporal Logic**: Scenarios like HOME-01 ("immediately after") rely on time awareness. Our current Heuristic Matcher (CBR) matches *state*, not *state transitions*.
    *   *Fix*: This is acceptable for MVP. Complex temporal patterns belong in the "Pattern Detector" (System 2 background job), not the fast path.
*   **Scope Leak**: GAME-02 ("new high score") is global.
    *   *Fix*: Ensure the embedding includes the `source` or `domain` in the vector, or enforce strict source filtering in the SQL query alongside the vector match.

### 3. Conclusion
The "System 2" (LLM) part of the loop is functioning correctly. It generates high-quality inputs for "System 1".

**Next Step Recommendation**: Proceed to **Option C (Integration)**. Since we now trust the *inputs* (the heuristics), we can confidently test the *mechanism* (storage + retrieval + matching) without worrying that garbage data is the cause of failure.
